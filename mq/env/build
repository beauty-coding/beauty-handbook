## docker 安装
#### 环境 
```text
win10
docker-desktop
```
#### 安装命令
```shell script
#下载镜像
docker pull zookeeper
docker pull wurstmeister/kafka
#查看镜像
docker images
#启动zookeeper
 docker run -d --name zookeeper -p 2181:2181 -v /etc/localtime:/etc/localtime zookeeper:latest   
 #启动kafka ，服务器是试用的阿里云的 这里就不隐藏了
docker run  -d --name kafka -p 9092:9092 -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=192.168.78.1:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.78.1:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -t wurstmeister/kafka
#进入kafka目录, ctrl+p+q 退出kafka容器，但不关闭容器
docker exec -ti kafka /bin/bash
#  进入到指定目录。  kafka_2.12-2.2.0 该目录的版本号可能不一致 自行修改不要直接复制
cd bin
#创建topic localhost 可能需要换成ip
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic demo
#查看topic
kafka-topics.sh --list --zookeeper localhost:2181
```
#### pom 依赖
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

#### yml配置
```yaml
spring:
  kafka:
    bootstrap-servers: {ip}:9092 #指定kafka server的地址，集群配多个，中间，逗号隔开
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: default_consumer_group #群组ID
      enable-auto-commit: true
      auto-commit-interval: 1000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
```
